{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone --branch test https://github.com/mibijoy007/EasyOCR.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bijoy\\miniconda3\\envs\\.enveasyocr\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu113\n"
     ]
    }
   ],
   "source": [
    "# extra\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:23.488642Z",
     "start_time": "2021-07-23T04:19:21.854534Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import yaml\n",
    "\n",
    "from utils import AttrDict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:23.885144Z",
     "start_time": "2021-07-23T04:19:23.880564Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:24.119144Z",
     "start_time": "2021-07-23T04:19:24.112032Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_config(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf8\") as stream:\n",
    "        opt = yaml.safe_load(stream)\n",
    "    opt = AttrDict(opt)\n",
    "    if opt.lang_char == 'None':\n",
    "        characters = ''\n",
    "        for data in opt['select_data'].split('-'):\n",
    "            csv_path = os.path.join(opt['train_data'], data, 'labels.csv')\n",
    "            # csv_path = os.path.join(opt['train_data'], data, './all_data/en_filtered/labels.csv')\n",
    "            print(\"inside get_config\",data)\n",
    "            df = pd.read_csv(csv_path, sep='^([^,]+),', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
    "            all_char = ''.join(df['words'])\n",
    "            characters += ''.join(set(all_char))\n",
    "        characters = sorted(set(characters))\n",
    "        opt.character= ''.join(characters)\n",
    "    else:\n",
    "        opt.character = opt.number + opt.symbol + opt.lang_char\n",
    "    os.makedirs(f'./saved_models/{opt.experiment_name}', exist_ok=True)\n",
    "    return opt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image0.jpeg</td>\n",
       "      <td>ঢাকা মেট্রো-গ ২৯-৫১৬৫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image1.jpeg</td>\n",
       "      <td>ঢাকা মেট্রো-চ ১৯-৫৪০৯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image2.jpeg</td>\n",
       "      <td>ঢাকা মেট্রো-চ ১৬-০৪৪০</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image3.jpeg</td>\n",
       "      <td>যশোর ট ১১-৩৭৩৬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image4.jpeg</td>\n",
       "      <td>যশোর ট ১১-৫৭৬৯</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                  words\n",
       "0  image0.jpeg  ঢাকা মেট্রো-গ ২৯-৫১৬৫\n",
       "1  image1.jpeg  ঢাকা মেট্রো-চ ১৯-৫৪০৯\n",
       "2  image2.jpeg  ঢাকা মেট্রো-চ ১৬-০৪৪০\n",
       "3  image3.jpeg         যশোর ট ১১-৩৭৩৬\n",
       "4  image4.jpeg         যশোর ট ১১-৫৭৬৯"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"all_data/en_filtered/labels.csv\", sep=',', usecols=['filename', 'words'], engine='python', keep_default_na=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:49:07.045060Z",
     "start_time": "2021-07-23T04:20:15.050992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./all_data/en_filtered\n"
     ]
    }
   ],
   "source": [
    "opt = get_config(\"config_files/en_filtered_config.yaml\")\n",
    "# train(opt = opt, amp=False)\n",
    "# the following train is a module(file)\n",
    "from importlib import reload\n",
    "import train\n",
    "reload(train)\n",
    "\n",
    "# the following train is a function inside same nammed > module(file)\n",
    "from train import train\n",
    "\n",
    "print(opt)\n",
    "# %run dataset.py\n",
    "# train(opt, amp=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: ./all_data/en_filtered\n",
      "opt.select_data: ['./all_data/en_filtered']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    ./all_data/en_filtered\t dataset: ./all_data/en_filtered\n",
      "./all_data/en_filtered/\n",
      "sub-directory:\t/.\t num samples: 29\n",
      "num total samples of ./all_data/en_filtered: 29 x 1.0 (total_data_usage_ratio) = 29\n",
      "num samples of ./all_data/en_filtered per batch: 32 x 1.0 (batch_ratio) = 32\n",
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 32 = 32\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    ./all_data/en_filtered\t dataset: /\n",
      "./all_data/en_filtered/\n",
      "sub-directory:\t/.\t num samples: 29\n",
      "--------------------------------------------------------------------------------\n",
      "No Transformation module specified\n",
      "model input parameters 32 400 20 1 512 512 242 34 None ResNet BiLSTM CTC\n",
      "Model:\n",
      "DataParallel(\n",
      "  (module): Model(\n",
      "    (FeatureExtraction): ResNet_FeatureExtractor(\n",
      "      (ConvNet): ResNet(\n",
      "        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (layer1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (layer2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
      "        (layer3): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (layer4): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
      "        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "    (SequenceModeling): Sequential(\n",
      "      (0): BidirectionalLSTM(\n",
      "        (rnn): LSTM(512, 512, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      )\n",
      "      (1): BidirectionalLSTM(\n",
      "        (rnn): LSTM(512, 512, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (Prediction): Linear(in_features=512, out_features=242, bias=True)\n",
      "  )\n",
      ")\n",
      "Modules, Parameters\n",
      "module.FeatureExtraction.ConvNet.conv0_1.weight 288\n",
      "module.FeatureExtraction.ConvNet.bn0_1.weight 32\n",
      "module.FeatureExtraction.ConvNet.bn0_1.bias 32\n",
      "module.FeatureExtraction.ConvNet.conv0_2.weight 18432\n",
      "module.FeatureExtraction.ConvNet.bn0_2.weight 64\n",
      "module.FeatureExtraction.ConvNet.bn0_2.bias 64\n",
      "module.FeatureExtraction.ConvNet.layer1.0.conv1.weight 73728\n",
      "module.FeatureExtraction.ConvNet.layer1.0.bn1.weight 128\n",
      "module.FeatureExtraction.ConvNet.layer1.0.bn1.bias 128\n",
      "module.FeatureExtraction.ConvNet.layer1.0.conv2.weight 147456\n",
      "module.FeatureExtraction.ConvNet.layer1.0.bn2.weight 128\n",
      "module.FeatureExtraction.ConvNet.layer1.0.bn2.bias 128\n",
      "module.FeatureExtraction.ConvNet.layer1.0.downsample.0.weight 8192\n",
      "module.FeatureExtraction.ConvNet.layer1.0.downsample.1.weight 128\n",
      "module.FeatureExtraction.ConvNet.layer1.0.downsample.1.bias 128\n",
      "module.FeatureExtraction.ConvNet.conv1.weight 147456\n",
      "module.FeatureExtraction.ConvNet.bn1.weight 128\n",
      "module.FeatureExtraction.ConvNet.bn1.bias 128\n",
      "module.FeatureExtraction.ConvNet.layer2.0.conv1.weight 294912\n",
      "module.FeatureExtraction.ConvNet.layer2.0.bn1.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer2.0.bn1.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer2.0.conv2.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer2.0.bn2.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer2.0.bn2.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer2.0.downsample.0.weight 32768\n",
      "module.FeatureExtraction.ConvNet.layer2.0.downsample.1.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer2.0.downsample.1.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer2.1.conv1.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer2.1.bn1.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer2.1.bn1.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer2.1.conv2.weight 589824\n",
      "module.FeatureExtraction.ConvNet.layer2.1.bn2.weight 256\n",
      "module.FeatureExtraction.ConvNet.layer2.1.bn2.bias 256\n",
      "module.FeatureExtraction.ConvNet.conv2.weight 589824\n",
      "module.FeatureExtraction.ConvNet.bn2.weight 256\n",
      "module.FeatureExtraction.ConvNet.bn2.bias 256\n",
      "module.FeatureExtraction.ConvNet.layer3.0.conv1.weight 1179648\n",
      "module.FeatureExtraction.ConvNet.layer3.0.bn1.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer3.0.bn1.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer3.0.conv2.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer3.0.bn2.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer3.0.bn2.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer3.0.downsample.0.weight 131072\n",
      "module.FeatureExtraction.ConvNet.layer3.0.downsample.1.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer3.0.downsample.1.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer3.1.conv1.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer3.1.bn1.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer3.1.bn1.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer3.1.conv2.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer3.1.bn2.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer3.1.bn2.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer3.2.conv1.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer3.2.bn1.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer3.2.bn1.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer3.2.conv2.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer3.2.bn2.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer3.2.bn2.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer3.3.conv1.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer3.3.bn1.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer3.3.bn1.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer3.3.conv2.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer3.3.bn2.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer3.3.bn2.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer3.4.conv1.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer3.4.bn1.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer3.4.bn1.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer3.4.conv2.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer3.4.bn2.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer3.4.bn2.bias 512\n",
      "module.FeatureExtraction.ConvNet.conv3.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.bn3.weight 512\n",
      "module.FeatureExtraction.ConvNet.bn3.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer4.0.conv1.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer4.0.bn1.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer4.0.bn1.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer4.0.conv2.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer4.0.bn2.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer4.0.bn2.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer4.1.conv1.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer4.1.bn1.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer4.1.bn1.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer4.1.conv2.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer4.1.bn2.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer4.1.bn2.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer4.2.conv1.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer4.2.bn1.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer4.2.bn1.bias 512\n",
      "module.FeatureExtraction.ConvNet.layer4.2.conv2.weight 2359296\n",
      "module.FeatureExtraction.ConvNet.layer4.2.bn2.weight 512\n",
      "module.FeatureExtraction.ConvNet.layer4.2.bn2.bias 512\n",
      "module.FeatureExtraction.ConvNet.conv4_1.weight 1048576\n",
      "module.FeatureExtraction.ConvNet.bn4_1.weight 512\n",
      "module.FeatureExtraction.ConvNet.bn4_1.bias 512\n",
      "module.FeatureExtraction.ConvNet.conv4_2.weight 1048576\n",
      "module.FeatureExtraction.ConvNet.bn4_2.weight 512\n",
      "module.FeatureExtraction.ConvNet.bn4_2.bias 512\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0 1048576\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0 1048576\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0 2048\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0 2048\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0_reverse 1048576\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0_reverse 1048576\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0_reverse 2048\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0_reverse 2048\n",
      "module.SequenceModeling.0.linear.weight 524288\n",
      "module.SequenceModeling.0.linear.bias 512\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0 1048576\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0 1048576\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0 2048\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0 2048\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0_reverse 1048576\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0_reverse 1048576\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0_reverse 2048\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0_reverse 2048\n",
      "module.SequenceModeling.1.linear.weight 524288\n",
      "module.SequenceModeling.1.linear.bias 512\n",
      "module.Prediction.weight 123904\n",
      "module.Prediction.bias 242\n",
      "Total Trainable Params: 53842642\n",
      "Trainable params num :  53842642\n",
      "Optimizer:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "------------ Options -------------\n",
      "number: ০১২৩৪৫৬৭৮৯\n",
      "symbol: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ €\n",
      "lang_char:  ঢাকা যশোর খুলনা বগুড়া সিলেট ঝিনাইদহ চট্টগ্রাম গাজীপুর মেট্রো অ আ ই ঈ উ ঊ ঋ এ ঐ ও ঔ ক খ গ ঘ ঙ চ ছ জ ঝ ঞ ট ঠ ড ঢ ণ ত থ দ ধ ন প ফ ব ভ ম য র ল শ ষ স া  ি  ু ী  ূ  ৃ ে ৈ ো  ৌ ড় ঢ় য় ০ ১ ২ ৩ ৪ ৫ ৬ ৭ ৮ ৯\n",
      "experiment_name: bn_filtered\n",
      "train_data: ./all_data/en_filtered\n",
      "valid_data: ./all_data/en_filtered\n",
      "manualSeed: 1111\n",
      "workers: 2\n",
      "batch_size: 32\n",
      "num_iter: 700\n",
      "valInterval: 50\n",
      "saved_model: \n",
      "FT: False\n",
      "optim: adam\n",
      "lr: 0.0001\n",
      "beta1: 0.9\n",
      "rho: 0.95\n",
      "eps: 1e-08\n",
      "grad_clip: 5\n",
      "select_data: ['./all_data/en_filtered']\n",
      "batch_ratio: ['1']\n",
      "total_data_usage_ratio: 1.0\n",
      "batch_max_length: 34\n",
      "imgH: 32\n",
      "imgW: 400\n",
      "rgb: False\n",
      "contrast_adjust: 0.0\n",
      "sensitive: True\n",
      "PAD: True\n",
      "data_filtering_off: False\n",
      "Transformation: None\n",
      "FeatureExtraction: ResNet\n",
      "SequenceModeling: BiLSTM\n",
      "Prediction: CTC\n",
      "num_fiducial: 20\n",
      "input_channel: 1\n",
      "output_channel: 512\n",
      "hidden_size: 512\n",
      "decode: greedy\n",
      "new_prediction: False\n",
      "freeze_FeatureFxtraction: False\n",
      "freeze_SequenceModeling: False\n",
      "character: ০১২৩৪৫৬৭৮৯!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ € ঢাকা যশোর খুলনা বগুড়া সিলেট ঝিনাইদহ চট্টগ্রাম গাজীপুর মেট্রো অ আ ই ঈ উ ঊ ঋ এ ঐ ও ঔ ক খ গ ঘ ঙ চ ছ জ ঝ ঞ ট ঠ ড ঢ ণ ত থ দ ধ ন প ফ ব ভ ম য র ল শ ষ স া  ি  ু ী  ূ  ৃ ে ৈ ো  ৌ ড় ঢ় য় ০ ১ ২ ৩ ৪ ৫ ৬ ৭ ৮ ৯\n",
      "num_class: 242\n",
      "---------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32me:\\aaa-Now\\japan\\regular classes\\project\\computer_vision\\easyocr_test\\SutonnyMJ Regular\\EasyOCR\\trainer\\dataset.py:117\u001b[0m, in \u001b[0;36mBatch_Balanced_Dataset.get_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     image, text \u001b[38;5;241m=\u001b[39m \u001b[43mdata_loader_iter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     balanced_batch_images\u001b[38;5;241m.\u001b[39mappend(image)\n",
      "File \u001b[1;32mc:\\Users\\Bijoy\\miniconda3\\envs\\.enveasyocr\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Bijoy\\miniconda3\\envs\\.enveasyocr\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1320\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_workers()\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \n\u001b[0;32m   1324\u001b[0m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\aaa-Now\\japan\\regular classes\\project\\computer_vision\\easyocr_test\\SutonnyMJ Regular\\EasyOCR\\trainer\\train.py:203\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(opt, show_number, amp)\u001b[0m\n\u001b[0;32m    201\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     image_tensors, labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m     image \u001b[38;5;241m=\u001b[39m image_tensors\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    205\u001b[0m     text, length \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mencode(labels, batch_max_length\u001b[38;5;241m=\u001b[39mopt\u001b[38;5;241m.\u001b[39mbatch_max_length)\n",
      "File \u001b[1;32me:\\aaa-Now\\japan\\regular classes\\project\\computer_vision\\easyocr_test\\SutonnyMJ Regular\\EasyOCR\\trainer\\dataset.py:122\u001b[0m, in \u001b[0;36mBatch_Balanced_Dataset.get_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_iter_list[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader_list[i])\n\u001b[1;32m--> 122\u001b[0m     image, text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader_iter_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     balanced_batch_images\u001b[38;5;241m.\u001b[39mappend(image)\n\u001b[0;32m    124\u001b[0m     balanced_batch_texts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text\n",
      "File \u001b[1;32mc:\\Users\\Bijoy\\miniconda3\\envs\\.enveasyocr\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Bijoy\\miniconda3\\envs\\.enveasyocr\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1330\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1330\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1333\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bijoy\\miniconda3\\envs\\.enveasyocr\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1286\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1286\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1287\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1288\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Bijoy\\miniconda3\\envs\\.enveasyocr\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1134\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bijoy\\miniconda3\\envs\\.enveasyocr\\lib\\queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    178\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\Bijoy\\miniconda3\\envs\\.enveasyocr\\lib\\threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 306\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(opt, amp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run train.py\n",
    "%run dataset.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing functions imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "from importlib import reload\n",
    "# import train\n",
    "# reload(train)\n",
    "from train import testabc\n",
    "testabc(2,6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".enveasyocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
